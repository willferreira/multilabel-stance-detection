{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import py\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import calc_scores, _tweet_score, calc_label_corr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_key = 'moral' # or 'bbc' or 'tweet'\n",
    "dataset_key = 'bbc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[local('/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-base_bbc.pkl'),\n",
       " local('/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-correlation_bbc.pkl'),\n",
       " local('/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-cross-label-dependency_bbc.pkl'),\n",
       " local('/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-correlation-global_bbc.pkl'),\n",
       " local('/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-multitask_bbc.pkl'),\n",
       " local('/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-powerset_bbc.pkl'),\n",
       " local('/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_fasttext-powerset_bbc.pkl'),\n",
       " local('/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_fasttext-binary-relevance_bbc.pkl')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = py.path.local('results/')\n",
    "files = path.listdir(fil='cv_results*.pkl')\n",
    "# files = sorted([fp for fp in files if fp.strpath.endswith('bbc.pkl')]) + sorted([fp for fp in files if not fp.strpath.endswith('bbc.pkl')])\n",
    "files = [f for f in files if dataset_key in f.strpath and ('mlp' in f.strpath or 'fasttext' in f.strpath) and 'Sandy' not in f.strpath]\n",
    "files = sorted(files, key=lambda s: s.strpath.split('-')[-1].split('.')[0])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-base_bbc.pkl\n",
      "Dispaying results for model_name: mlp-base, dataset: bbc\n",
      "Test set scores:\n",
      "                        accuracy        f1   jaccard precision    recall  \\\n",
      "agreement-disagreement  0.959677         0  0.959677         0         0   \n",
      "certainty               0.927419      0.25  0.927419       0.6  0.157895   \n",
      "contrariety             0.834677   0.70073  0.834677  0.695652  0.705882   \n",
      "hypotheticality         0.935484  0.757576  0.935484  0.925926  0.641026   \n",
      "necessity                  0.875  0.626506     0.875  0.764706  0.530612   \n",
      "prediction              0.810484  0.515464  0.810484  0.543478  0.490196   \n",
      "source-of-knowledge     0.822581  0.614035  0.822581  0.660377   0.57377   \n",
      "tact-rudeness           0.967742         0  0.967742         0         0   \n",
      "uncertainty             0.870968       0.6  0.870968  0.666667  0.545455   \n",
      "volition                 0.96371  0.181818   0.96371         1       0.1   \n",
      "OVERALL                 0.379032  0.424613  0.485685  0.585681  0.374484   \n",
      "\n",
      "                       zero_one_loss  \n",
      "agreement-disagreement     0.0403226  \n",
      "certainty                  0.0725806  \n",
      "contrariety                 0.165323  \n",
      "hypotheticality            0.0645161  \n",
      "necessity                      0.125  \n",
      "prediction                  0.189516  \n",
      "source-of-knowledge         0.177419  \n",
      "tact-rudeness              0.0322581  \n",
      "uncertainty                 0.129032  \n",
      "volition                   0.0362903  \n",
      "OVERALL                     0.620968  \n",
      "Best params: loss=binary_crossentropy\n",
      "\n",
      "Best score: 0.4338715102589976\n",
      "/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-correlation_bbc.pkl\n",
      "Dispaying results for model_name: mlp-correlation, dataset: bbc\n",
      "Test set scores:\n",
      "                        accuracy        f1   jaccard precision    recall  \\\n",
      "agreement-disagreement  0.955645         0  0.955645         0         0   \n",
      "certainty               0.935484  0.333333  0.935484       0.8  0.210526   \n",
      "contrariety             0.822581  0.710526  0.822581  0.642857  0.794118   \n",
      "hypotheticality         0.919355  0.677419  0.919355  0.913043  0.538462   \n",
      "necessity               0.879032  0.615385  0.879032  0.827586  0.489796   \n",
      "prediction              0.810484  0.505263  0.810484  0.545455  0.470588   \n",
      "source-of-knowledge     0.802419  0.550459  0.802419     0.625  0.491803   \n",
      "tact-rudeness           0.967742         0  0.967742         0         0   \n",
      "uncertainty                0.875  0.607595     0.875  0.685714  0.545455   \n",
      "volition                 0.96371  0.181818   0.96371         1       0.1   \n",
      "OVERALL                 0.354839   0.41818  0.468884  0.603966  0.364075   \n",
      "\n",
      "                       zero_one_loss  \n",
      "agreement-disagreement     0.0443548  \n",
      "certainty                  0.0645161  \n",
      "contrariety                 0.177419  \n",
      "hypotheticality            0.0806452  \n",
      "necessity                   0.120968  \n",
      "prediction                  0.189516  \n",
      "source-of-knowledge         0.197581  \n",
      "tact-rudeness              0.0322581  \n",
      "uncertainty                    0.125  \n",
      "volition                   0.0362903  \n",
      "OVERALL                     0.645161  \n",
      "Best params: loss=CorrelationLoss(alpha=0.00, threshold=0.30, y_pred=None\n",
      "\n",
      "Best score: 0.45650857719475274\n",
      "/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-cross-label-dependency_bbc.pkl\n",
      "Dispaying results for model_name: mlp-cross-label-dependency, dataset: bbc\n",
      "Test set scores:\n",
      "                        accuracy        f1   jaccard precision    recall  \\\n",
      "agreement-disagreement   0.96371  0.307692   0.96371  0.666667       0.2   \n",
      "certainty               0.915323  0.275862  0.915323       0.4  0.210526   \n",
      "contrariety             0.762097  0.654971  0.762097  0.543689  0.823529   \n",
      "hypotheticality         0.951613  0.846154  0.951613  0.846154  0.846154   \n",
      "necessity               0.866935  0.645161  0.866935  0.681818  0.612245   \n",
      "prediction              0.806452  0.563636  0.806452  0.525424  0.607843   \n",
      "source-of-knowledge         0.75  0.602564      0.75  0.494737  0.770492   \n",
      "tact-rudeness           0.971774  0.461538  0.971774       0.6     0.375   \n",
      "uncertainty             0.798387  0.561404  0.798387  0.457143  0.727273   \n",
      "volition                0.971774  0.461538  0.971774         1       0.3   \n",
      "OVERALL                 0.294355  0.538052  0.513306  0.621563  0.547306   \n",
      "\n",
      "                       zero_one_loss  \n",
      "agreement-disagreement     0.0362903  \n",
      "certainty                  0.0846774  \n",
      "contrariety                 0.237903  \n",
      "hypotheticality            0.0483871  \n",
      "necessity                   0.133065  \n",
      "prediction                  0.193548  \n",
      "source-of-knowledge             0.25  \n",
      "tact-rudeness              0.0282258  \n",
      "uncertainty                 0.201613  \n",
      "volition                   0.0282258  \n",
      "OVERALL                     0.705645  \n",
      "Best params: loss=CrossLabelDependencyLoss(alpha=0.50)\n",
      "\n",
      "Best score: 0.5078035654221326\n",
      "/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-correlation-global_bbc.pkl\n",
      "Dispaying results for model_name: mlp-correlation-global, dataset: bbc\n",
      "Test set scores:\n",
      "                        accuracy        f1   jaccard precision    recall  \\\n",
      "agreement-disagreement  0.959677         0  0.959677         0         0   \n",
      "certainty               0.931452  0.190476  0.931452         1  0.105263   \n",
      "contrariety             0.862903      0.75  0.862903      0.75      0.75   \n",
      "hypotheticality         0.923387  0.698413  0.923387  0.916667  0.564103   \n",
      "necessity                  0.875  0.607595     0.875       0.8  0.489796   \n",
      "prediction              0.802419  0.461538  0.802419     0.525  0.411765   \n",
      "source-of-knowledge     0.806452   0.54717  0.806452  0.644444   0.47541   \n",
      "tact-rudeness           0.967742         0  0.967742         0         0   \n",
      "uncertainty             0.842742  0.434783  0.842742       0.6  0.340909   \n",
      "volition                0.959677         0  0.959677         0         0   \n",
      "OVERALL                  0.33871  0.368997  0.447782  0.523611  0.313725   \n",
      "\n",
      "                       zero_one_loss  \n",
      "agreement-disagreement     0.0403226  \n",
      "certainty                  0.0685484  \n",
      "contrariety                 0.137097  \n",
      "hypotheticality            0.0766129  \n",
      "necessity                      0.125  \n",
      "prediction                  0.197581  \n",
      "source-of-knowledge         0.193548  \n",
      "tact-rudeness              0.0322581  \n",
      "uncertainty                 0.157258  \n",
      "volition                   0.0403226  \n",
      "OVERALL                      0.66129  \n",
      "Best params: loss=CorrelationLoss(alpha=0.10, threshold=0.50, y_pred=not None\n",
      "\n",
      "Best score: 0.427564749411369\n",
      "/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-multitask_bbc.pkl\n",
      "Dispaying results for model_name: mlp-multitask, dataset: bbc\n",
      "Test set scores:\n",
      "                        accuracy        f1   jaccard precision    recall  \\\n",
      "agreement-disagreement  0.955645         0  0.955645         0         0   \n",
      "certainty               0.927419  0.181818  0.927419  0.666667  0.105263   \n",
      "contrariety             0.842742  0.711111  0.842742  0.716418  0.705882   \n",
      "hypotheticality         0.927419  0.735294  0.927419  0.862069  0.641026   \n",
      "necessity               0.850806  0.463768  0.850806       0.8  0.326531   \n",
      "prediction              0.810484  0.447059  0.810484  0.558824  0.372549   \n",
      "source-of-knowledge      0.78629  0.569106   0.78629  0.564516   0.57377   \n",
      "tact-rudeness           0.967742         0  0.967742         0         0   \n",
      "uncertainty             0.862903  0.604651  0.862903  0.619048  0.590909   \n",
      "volition                0.971774  0.461538  0.971774         1       0.3   \n",
      "OVERALL                 0.314516  0.417435  0.435148  0.578754  0.361593   \n",
      "\n",
      "                       zero_one_loss  \n",
      "agreement-disagreement     0.0443548  \n",
      "certainty                  0.0725806  \n",
      "contrariety                 0.157258  \n",
      "hypotheticality            0.0725806  \n",
      "necessity                   0.149194  \n",
      "prediction                  0.189516  \n",
      "source-of-knowledge          0.21371  \n",
      "tact-rudeness              0.0322581  \n",
      "uncertainty                 0.137097  \n",
      "volition                   0.0282258  \n",
      "OVERALL                     0.685484  \n",
      "Best params: \n",
      "\n",
      "Best score: 0.4346451395896401\n",
      "/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_mlp-powerset_bbc.pkl\n",
      "Dispaying results for model_name: mlp-powerset, dataset: bbc\n",
      "Test set scores:\n",
      "                        accuracy        f1   jaccard precision    recall  \\\n",
      "agreement-disagreement  0.967742  0.428571  0.967742      0.75       0.3   \n",
      "certainty               0.915323      0.16  0.915323  0.333333  0.105263   \n",
      "contrariety             0.830645  0.691176  0.830645  0.691176  0.691176   \n",
      "hypotheticality         0.923387  0.732394  0.923387    0.8125  0.666667   \n",
      "necessity               0.899194  0.705882  0.899194  0.833333  0.612245   \n",
      "prediction              0.822581  0.568627  0.822581  0.568627  0.568627   \n",
      "source-of-knowledge     0.778226  0.580153  0.778226  0.542857  0.622951   \n",
      "tact-rudeness           0.967742         0  0.967742         0         0   \n",
      "uncertainty             0.879032  0.634146  0.879032  0.684211  0.590909   \n",
      "volition                0.979839  0.666667  0.979839         1       0.5   \n",
      "OVERALL                 0.439516  0.516762  0.555981  0.621604  0.465784   \n",
      "\n",
      "                       zero_one_loss  \n",
      "agreement-disagreement     0.0322581  \n",
      "certainty                  0.0846774  \n",
      "contrariety                 0.169355  \n",
      "hypotheticality            0.0766129  \n",
      "necessity                   0.100806  \n",
      "prediction                  0.177419  \n",
      "source-of-knowledge         0.221774  \n",
      "tact-rudeness              0.0322581  \n",
      "uncertainty                 0.120968  \n",
      "volition                   0.0201613  \n",
      "OVERALL                     0.560484  \n",
      "Best params: loss=categorical_crossentropy\n",
      "\n",
      "Best score: 0.5231416078035654\n",
      "/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_fasttext-powerset_bbc.pkl\n",
      "Dispaying results for model_name: fasttext-powerset, dataset: bbc\n",
      "Test set scores:\n",
      "                        accuracy        f1   jaccard precision    recall  \\\n",
      "agreement-disagreement  0.927419  0.181818  0.927419  0.166667       0.2   \n",
      "certainty               0.879032  0.117647  0.879032  0.133333  0.105263   \n",
      "contrariety             0.778226  0.586466  0.778226       0.6  0.573529   \n",
      "hypotheticality         0.899194  0.603175  0.899194  0.791667  0.487179   \n",
      "necessity               0.766129  0.325581  0.766129  0.378378  0.285714   \n",
      "prediction              0.782258    0.4375  0.782258  0.466667  0.411765   \n",
      "source-of-knowledge     0.709677  0.428571  0.709677  0.415385  0.442623   \n",
      "tact-rudeness            0.96371         0   0.96371         0         0   \n",
      "uncertainty             0.766129  0.369565  0.766129  0.354167  0.386364   \n",
      "volition                0.927419       0.1  0.927419       0.1       0.1   \n",
      "OVERALL                 0.233871  0.315032   0.36203  0.340626  0.299244   \n",
      "\n",
      "                       zero_one_loss  \n",
      "agreement-disagreement     0.0725806  \n",
      "certainty                   0.120968  \n",
      "contrariety                 0.221774  \n",
      "hypotheticality             0.100806  \n",
      "necessity                   0.233871  \n",
      "prediction                  0.217742  \n",
      "source-of-knowledge         0.290323  \n",
      "tact-rudeness              0.0362903  \n",
      "uncertainty                 0.233871  \n",
      "volition                   0.0725806  \n",
      "OVERALL                     0.766129  \n",
      "Best params: dim=300,word_ngrams=1\n",
      "\n",
      "Best score: 0.42373023881601074\n",
      "/Users/williamferreira/dev/multilabel-stance-detection/results/cv_results_fasttext-binary-relevance_bbc.pkl\n",
      "Dispaying results for model_name: fasttext-binary-relevance, dataset: bbc\n",
      "Test set scores:\n",
      "                        accuracy        f1   jaccard precision    recall  \\\n",
      "agreement-disagreement  0.959677  0.166667  0.959677       0.5       0.1   \n",
      "certainty               0.919355  0.230769  0.919355  0.428571  0.157895   \n",
      "contrariety             0.782258     0.625  0.782258  0.592105  0.661765   \n",
      "hypotheticality         0.915323  0.686567  0.915323  0.821429  0.589744   \n",
      "necessity               0.846774     0.525  0.846774  0.677419  0.428571   \n",
      "prediction              0.810484  0.447059  0.810484  0.558824  0.372549   \n",
      "source-of-knowledge     0.782258  0.490566  0.782258  0.577778   0.42623   \n",
      "tact-rudeness           0.967742         0  0.967742         0         0   \n",
      "uncertainty             0.895161  0.690476  0.895161     0.725  0.659091   \n",
      "volition                0.967742  0.428571  0.967742      0.75       0.3   \n",
      "OVERALL                 0.278226  0.429068  0.397177  0.563113  0.369584   \n",
      "\n",
      "                       zero_one_loss  \n",
      "agreement-disagreement     0.0403226  \n",
      "certainty                  0.0806452  \n",
      "contrariety                 0.217742  \n",
      "hypotheticality            0.0846774  \n",
      "necessity                   0.153226  \n",
      "prediction                  0.189516  \n",
      "source-of-knowledge         0.217742  \n",
      "tact-rudeness              0.0322581  \n",
      "uncertainty                 0.104839  \n",
      "volition                   0.0322581  \n",
      "OVERALL                     0.721774  \n",
      "Best params: dim=300,word_ngrams=1\n",
      "\n",
      "Best score: 0.3849310460813992\n"
     ]
    }
   ],
   "source": [
    "all_tweet_scores = defaultdict(defaultdict)\n",
    "multilabel_scores = {}\n",
    "for f in files:\n",
    "    print(f)\n",
    "    with open(f.strpath, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    model_name = results['model_name']\n",
    "    dataset_name = results['dataset_name']\n",
    "    print('Dispaying results for model_name: {}, dataset: {}'\\\n",
    "              .format(model_name, dataset_name))\n",
    "    \n",
    "    y_true = results['y_test']\n",
    "    y_pred = results['y_pred']\n",
    "    print('Test set scores:')\n",
    "    if results['dataset_name'] == 'bbc' or results['dataset_name'].startswith('moral'):\n",
    "        scores = calc_scores(y_true, y_pred)\n",
    "        print(scores)\n",
    "        multilabel_scores[(model_name, dataset_name)] = scores.loc['OVERALL', :]\n",
    "    else:\n",
    "        tweet_score = _tweet_score(y_true.values, y_pred)\n",
    "        all_tweet_scores[model_name][dataset_name] = tweet_score\n",
    "        print('Test set macro-averaged F1-score: {}'.format(tweet_score))\n",
    "    print('Best params: {}\\n'.format(','.join(['{}={}'.format(k.split('__')[-1], v) for k, v in results['best_params'].items()])))\n",
    "    print('Best score: {}'.format(results['best_score']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext-binary-relevance     0.397177\n",
      "fasttext-powerset             0.362030\n",
      "mlp-base                      0.485685\n",
      "mlp-correlation               0.468884\n",
      "mlp-correlation-global        0.447782\n",
      "mlp-cross-label-dependency    0.513306\n",
      "mlp-multitask                 0.435148\n",
      "mlp-powerset                  0.555981\n",
      "Name: jaccard, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if dataset_key == 'tweet':\n",
    "    for m, d in all_tweet_scores.items():\n",
    "        print(m, np.round(np.mean([list(d.values())]) * 100, 2))\n",
    "else:\n",
    "    df = pd.DataFrame(multilabel_scores)\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.columns)\n",
    "    df = df.T[['jaccard', 'accuracy', 'f1']].sort_index(level=1)\n",
    "    print(df['jaccard'].groupby(level=[0, 1]).max().groupby(level=0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mlp-base</th>\n",
       "      <th>mlp-correlation</th>\n",
       "      <th>mlp-cross-label-dependency</th>\n",
       "      <th>mlp-correlation-global</th>\n",
       "      <th>mlp-multitask</th>\n",
       "      <th>mlp-powerset</th>\n",
       "      <th>fasttext-powerset</th>\n",
       "      <th>fasttext-binary-relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>bbc</th>\n",
       "      <th>bbc</th>\n",
       "      <th>bbc</th>\n",
       "      <th>bbc</th>\n",
       "      <th>bbc</th>\n",
       "      <th>bbc</th>\n",
       "      <th>bbc</th>\n",
       "      <th>bbc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.379032</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.294355</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>0.314516</td>\n",
       "      <td>0.439516</td>\n",
       "      <td>0.233871</td>\n",
       "      <td>0.278226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.424613</td>\n",
       "      <td>0.41818</td>\n",
       "      <td>0.538052</td>\n",
       "      <td>0.368997</td>\n",
       "      <td>0.417435</td>\n",
       "      <td>0.516762</td>\n",
       "      <td>0.315032</td>\n",
       "      <td>0.429068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard</th>\n",
       "      <td>0.485685</td>\n",
       "      <td>0.468884</td>\n",
       "      <td>0.513306</td>\n",
       "      <td>0.447782</td>\n",
       "      <td>0.435148</td>\n",
       "      <td>0.555981</td>\n",
       "      <td>0.36203</td>\n",
       "      <td>0.397177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.585681</td>\n",
       "      <td>0.603966</td>\n",
       "      <td>0.621563</td>\n",
       "      <td>0.523611</td>\n",
       "      <td>0.578754</td>\n",
       "      <td>0.621604</td>\n",
       "      <td>0.340626</td>\n",
       "      <td>0.563113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.374484</td>\n",
       "      <td>0.364075</td>\n",
       "      <td>0.547306</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.361593</td>\n",
       "      <td>0.465784</td>\n",
       "      <td>0.299244</td>\n",
       "      <td>0.369584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero_one_loss</th>\n",
       "      <td>0.620968</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.705645</td>\n",
       "      <td>0.66129</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.560484</td>\n",
       "      <td>0.766129</td>\n",
       "      <td>0.721774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mlp-base mlp-correlation mlp-cross-label-dependency  \\\n",
       "                    bbc             bbc                        bbc   \n",
       "accuracy       0.379032        0.354839                   0.294355   \n",
       "f1             0.424613         0.41818                   0.538052   \n",
       "jaccard        0.485685        0.468884                   0.513306   \n",
       "precision      0.585681        0.603966                   0.621563   \n",
       "recall         0.374484        0.364075                   0.547306   \n",
       "zero_one_loss  0.620968        0.645161                   0.705645   \n",
       "\n",
       "              mlp-correlation-global mlp-multitask mlp-powerset  \\\n",
       "                                 bbc           bbc          bbc   \n",
       "accuracy                     0.33871      0.314516     0.439516   \n",
       "f1                          0.368997      0.417435     0.516762   \n",
       "jaccard                     0.447782      0.435148     0.555981   \n",
       "precision                   0.523611      0.578754     0.621604   \n",
       "recall                      0.313725      0.361593     0.465784   \n",
       "zero_one_loss                0.66129      0.685484     0.560484   \n",
       "\n",
       "              fasttext-powerset fasttext-binary-relevance  \n",
       "                            bbc                       bbc  \n",
       "accuracy               0.233871                  0.278226  \n",
       "f1                     0.315032                  0.429068  \n",
       "jaccard                 0.36203                  0.397177  \n",
       "precision              0.340626                  0.563113  \n",
       "recall                 0.299244                  0.369584  \n",
       "zero_one_loss          0.766129                  0.721774  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(multilabel_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
